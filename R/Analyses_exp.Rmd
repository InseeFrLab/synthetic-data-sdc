---
title: "Analyses des simulations"
author: "Julien Helfenstein"
date: "`r Sys.Date()`"
output: html_document
---

```{r packages}
source("Analyses.R")
```

```{r données}
data <- res_simul 
```

## Vue d'ensemble

```{r}
table_cat
table_mean_num
```

## Correlations

```{r correlations}
cor_comp
somme_cor_mat
```

liste_mat est une liste de 6 matrices. Ces matrices sont les matrices de corrélations moyenne des simulations pour chaque modèles moins la matrice de corrélation du jeu de données original.

somme_cor_mat est la somme des éléments de chaque matrices. Plus la valeur est proche de 0 plus les synthétisations produisent de bonnes corrélations.

bag et cart sont ici les meilleurs modèles suivis par parametric, ctree et rf. Sample est loin derrière.

## MAE
```{r mae}
  table_mae
```
On remarque que bag et rf ont des MAE très élevé allant jusqu'à être 10 fois supérieurs aux autres modèles. Sample, cart, ctree et parametric sont assez rapprochés sans qu'il n'y ait une réelle domination d'un modèle. 

## MSE
```{r mse}
  table_mse
```
On ne voit pas de réelle domination d'un modèle.


## Analyse de l'IMC

On va vérifier deux choses :

-   Est-ce que dans les jeux de données synthétiques la variable bmi est bien synthétisé, i.e est-ce qu'elle respecte bmi = 10000 \* (weight / height \^ 2) ?

-   Est-ce que les valeurs de la variable bmi synthétisée sont proches de celles de la variable bmi originale ?

```{r bmi comparaison}
bmi_comp(data)
```

1)  On constate une assez bonne synthétisation via cart, ctree, parametric et bag, une moins bonne synthétisation via rf et une vraiment moins bonne synthétisation via sample. On n'a cependant pas une valeur de 0 ce qui signifie que le modèle s'approche de la relation mais ne la reproduit pas totalement.

2)  En ce qui concerne la comparaison au jeu de données original, sample, cart, ctree et bagging s'en sortent le mieux, suivis par rf puis parametric.

```{r}
  reg_coeff[2, ]
```
reg_coeff est un vecteur comportant la moyenne des coefficients directeurs pour chaque modèles.

On voit que bag, cart et ctree sont très proches, suivis par parametric (x5), rf(x11). Sample est à la ramasse

```{r graphiques bmi}
modele = 2
i=1
plot_nuage_bmi(modele, i)

plot_reg_bmi()

densites(res_simul)
```
Les densités de sample, cart, et ctree sont très ressemblantes. Celles de bag et rf le sont entre elles. 


## Mesures d'utilités
```{r utilite}
utility_measures_all_meth
```


```{r graphiques utilite}
utility_measures_all_meth <- utility_measures_all_meth %>%
  group_by(method) %>% 
  mutate(i = 1:500) %>% 
  mutate(across(pMSE:U, cummean, .names = "{.col}_cummean"))

utility_measures_all_meth %>% 
  ggplot() +
  geom_line(aes(x = i, y = pMSE_cummean, col = method))


utility_graph <- map(
  c("pMSE","SPECKS","PO50","U"),
  \(meth){
    utility_measures_all_meth %>% 
      ggplot( aes(x=method, y=.data[[meth]], fill=method)) +
      geom_violin(width=1.4) +
      geom_boxplot(width=0.1, color="grey", alpha=0.2) +
      scale_fill_viridis(discrete = TRUE) +
      coord_flip() +
      theme_ipsum() +
      theme(
        legend.position="none",
        plot.title = element_text(size=11)
      ) +
      ggtitle(paste0("distribution des ", meth)) +
      ylab(meth) + xlab("méthode")
  }
)
names(utility_graph) <- c("pMSE","SPECKS","PO50","U")
utility_graph$pMSE
utility_graph$SPECKS
utility_graph$PO50
utility_graph$U

utility_measures_summary <- utility_measures_all_meth %>% 
  group_by(method) %>% 
  summarise(
    across(
      pMSE:U, 
      list(mean = mean, min = min, max = max, 
           pc025 = ~quantile(., probs = 0.025),
           pc975 = ~quantile(., probs = 0.975),
           sd = sd
      ),
      .names = "{.col}_{.fn}"
    )) %>%
  tidyr::pivot_longer(-1, names_to = "indicateur", values_to = "val") %>% 
  tidyr::separate(indicateur, into = c("utility","indicateur"))

utility_measures_summary %>% 
  filter(indicateur == "mean") %>%
  ggplot() +
  geom_bar(aes(x = method, y = val, fill = utility), stat = "identity")+
  coord_flip() +
  facet_wrap(~utility, scales = "free") +
  theme_ipsum()
```
1) Sur le premier graphique, on remarque que les moyennes cumulées se stabilisent très rapidement. On remarque de plus que cart est le meilleur modèle en terme de pMSE. Il est suivi par rf, bag et ctree. Parametric arrive ensuite avec un pMSE environ 2 fois plus élevé. Enfin, sample a un pMSE d'environ de l'ordre de 7 fois supérieur.

2) On constate que pour la plupart des modèles, l'étendue du pMSE est relativement contenue à l'exception de sample. Cart est ici le meilleur et sample est le moins bon et de loin.

3) Concernant le SPECKS, on obtient les mêmes conclusions que pour le pMSE. On rappelle que le SPECKS est défini par : $$SPECKS =  \sup_{\hat{p}}|F_{t=0}(\hat{p}_i) - \hat{F}_{t=1}(\hat{p}_i)|$$ où $F$ est la fonction de répartition
4) De même pour le PO50. On rappelle qu'il est défini par : $$PO50 =  100 \frac{\sum_i t_i(\hat{p}_i>c) + (1-t_i)(\hat{p}_i<c)}{\sum_i (\hat{p}_i \neq c)} - 50$$
5) Enfin, pour le U, la différence est moins flagrante mais toujours avec sample en dernière place. On rappelle qu'il est défini par : La somme des rangs de $\hat{p}_i$ où $t_i = 1$ dans l'ordre de $\hat{p}_i$

## Recherche des individus répliqués
```{r repliques}
nb_repliques_all_meth %>% 
  group_by(method) %>% 
  summarise(across(n_replicats, list(mean=mean, min=min, max=max, sd=sd)))
```
Les modèles parametric et sample ne produisent aucun individu répliqué.
Pour ctree, sur 500 synthétisations, 1 jeu de données possède au moins un individu répliqué
Cart produit en moyenne 1 jeu de données




