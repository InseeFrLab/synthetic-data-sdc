---
title: "Analyses des simulations"
author: "Julien Helfenstein"
date: "24/05/2024"
output: html_document
---

```{r donnees}
source("Analyses.R")
```

## Vue d'ensemble

```{r}
analyses$table_cat
analyses$table_mean_num
```

## Correlations

```{r correlations}
source("~/work/synthetic-data-sdc/R/fonctions/Correlations.R")
table_cor
analyses$somme_cor_mat
```

liste_mat est une liste de 6 matrices. Ces matrices sont les matrices de corrélations moyenne des simulations pour chaque modèles moins la matrice de corrélation du jeu de données original.

somme_cor_mat est la somme des éléments de chaque matrices. Plus la valeur est proche de 0 plus les synthétisations conservent de bonnes corrélations.

bag et cart sont ici les meilleurs modèles suivis par parametric, ctree et rf. Sample est loin derrière.

## MAE
```{r mae}
analyses$table_mae
```
On remarque que bag et rf ont des MAE très élevé allant jusqu'à être 10 fois supérieurs aux autres modèles. Sample, cart, ctree et parametric sont assez rapprochés sans qu'il n'y ait une réelle domination d'un modèle. 

## MSE
```{r mse}
analyses$table_mse
```
On ne voit pas de réelle domination d'un modèle.


## Analyse de bmi

On va vérifier deux choses :

-   Est-ce que dans les jeux de données synthétiques la variable bmi est bien synthétisé, i.e est-ce qu'elle respecte bmi = 10000 \* (weight / height \^ 2) ?

-   Est-ce que les valeurs de la variable bmi synthétisée sont proches de celles de la variable bmi originale ?

```{r bmi comparaison}
source("~/work/synthetic-data-sdc/R/fonctions/Graphiques.R")
bmi_comp(data)
```
Cette matrice montre les écarts moyen entre le bmi synthétique et le bmi original puis entre le bmi synthétisé et le bmi original.

Cart, ctreeet bag ont des bmi synthétiques proches des bmi synthétisés. Rf a un bmi synthétique meilleur que son bmi synthétisé. Parametric lui a un bmi synthétisé meilleur que son bmi synthétique.

```{r ks test}
KS_test(data)
```
Cette matrice comporte les p-valeurs moyenne des tests de Kolmogov-Smirnov. On apperçoit qu'elles sont toutes largement au-dessus de 0.05, donc dans l'ensemble les distributions ne sont pas significativement différentes de celle pour le jeu de données original. Cependant, pour la variable bmi pour parametric, on remarque que la p-valeur est proche de 0.05. On ne va donc pas rejetter aussi assurément que les distributions ne sont pas différentes.

```{r}
analyses$reg_coeff[2, ]
```
reg_coeff est un vecteur comportant la moyenne des coefficients directeurs pour chaque modèles.

On voit que bag, cart et ctree sont très proches, suivis par parametric (x5), rf(x11). Sample est à la ramasse

```{r graphiques bmi}
source("~/work/synthetic-data-sdc/R/fonctions/Densites.R")
modele = "sample"
num_dataset = 1
plot_nuage_bmi(modele, num_dataset)

plot_reg_bmi()

plot_dens_comb(data, "bmi")
plot_dens_syn_org(data, "bmi")

plot_dens_syn_org(data, "height")
plot_dens_syn_org(data, "weight")
```
Les densités de sample, cart, et ctree sont très ressemblantes. Celles de bag et rf le sont entre elles.

On remarque des pics sur les densités, on regarde donc les densités de height et weight pour voir s'ils viennent de là et en effet c'est le cas.

```{r cdf}
source("~/work/synthetic-data-sdc/R/fonctions/Graphiques.R")
CDF(data, "cart", "bmi", 1)
```

```{r bmi syn vs syn}
dens_bmi()
```

```{r differences aires}
densite_diff(data, "bmi")[[1]]

bp_densite(data, "bmi")

for (i in 1:length(varsnum)) {
  print(bp_densite(data, varsnum[i]))
}
```
On constate que parametric est le modèle ayant l'aire moyenne de la densité de la variable bmi se rapprochant le plus de la densité de la variable bmi originale. Il est aussi le modèle ayant la plus petite variabilité. Cart est le modèle ayant la plus grande variabilté.


## Mesures d'utilités
```{r utilite}
analyses$utility_measures_all_meth
```


```{r graphiques utilite}
source("~/work/synthetic-data-sdc/R/fonctions/Utilite.R")
moycum_mesures()

distribution_mesures()

resume_mesures()
```
1) Sur le premier graphique, on remarque que les moyennes cumulées se stabilisent très rapidement. On remarque de plus que cart est le meilleur modèle en terme de pMSE. Il est suivi par rf, bag et ctree. Parametric arrive ensuite avec un pMSE environ 2 fois plus élevé. Enfin, sample a un pMSE d'environ de l'ordre de 7 fois supérieur.

2) On constate que pour la plupart des modèles, l'étendue du pMSE est relativement contenue à l'exception de sample. Cart est ici le meilleur et sample est le moins bon et de loin.

3) Concernant le SPECKS, on obtient les mêmes conclusions que pour le pMSE. On rappelle que le SPECKS est défini par : $$SPECKS =  \sup_{\hat{p}}|F_{t=0}(\hat{p}_i) - \hat{F}_{t=1}(\hat{p}_i)|$$ où $F$ est la fonction de répartition
4) De même pour le PO50. On rappelle qu'il est défini par : $$PO50 =  100 \frac{\sum_i t_i(\hat{p}_i>c) + (1-t_i)(\hat{p}_i<c)}{\sum_i (\hat{p}_i \neq c)} - 50$$
5) Enfin, pour le U, la différence est moins flagrante mais toujours avec sample en dernière place. On rappelle qu'il est défini par : La somme des rangs de $\hat{p}_i$ où $t_i = 1$ dans l'ordre de $\hat{p}_i$

## Recherche des individus répliqués
```{r repliques}
analyses$nb_repliques_all_meth %>% 
  group_by(method) %>% 
  summarise(across(n_replicats, list(mean=mean, min=min, max=max, sd=sd)))
```
Les modèles parametric et sample ne produisent aucun individu répliqué.
Pour ctree, sur 500 synthétisations, 1 jeu de données possède au moins un individu répliqué
Cart produit en moyenne 1 jeu de données


